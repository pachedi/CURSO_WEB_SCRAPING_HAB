new_height
# Obtener la altura actual de la página
previous_height <- driver$executeScript("return document.body.scrollHeight")
# Obtener la altura actual de la página
previous_height <- remDr$executeScript("return document.body.scrollHeight")
previous_height
# Desplazarse al final
driver$executeScript("window.scrollTo(0, document.body.scrollHeight);")
# Desplazarse al final
remDr$executeScript("window.scrollTo(0, document.body.scrollHeight);")
# Verificar si la altura cambió
new_height <- remDr$executeScript("return document.body.scrollHeight")
new_height
new_height == previous_height
new_height[1]
new_height[[1]]
new_height[[1]] == previous_height[[1]]
for (i in 1:max_attempts) {
# Obtener la altura actual de la página
previous_height <- remDr$executeScript("return document.body.scrollHeight")
# Desplazarse al final
remDr$executeScript("window.scrollTo(0, document.body.scrollHeight);")
# Esperar un momento para permitir que se cargue el contenido
Sys.sleep(delay)
# Verificar si la altura cambió
new_height <- remDr$executeScript("return document.body.scrollHeight")
if (new_height[[1]] == previous_height[[1]]) {
message("Se alcanzó el final de la página.")
break
}
}
# Función para desplazarse al final de la página
scroll_to_bottom <- function(driver, max_attempts = 10, delay = 2) {
for (i in 1:max_attempts) {
# Obtener la altura actual de la página
previous_height <- remDr$executeScript("return document.body.scrollHeight")
# Desplazarse al final
remDr$executeScript("window.scrollTo(0, document.body.scrollHeight);")
# Esperar un momento para permitir que se cargue el contenido
Sys.sleep(delay)
# Verificar si la altura cambió
new_height <- remDr$executeScript("return document.body.scrollHeight")
if (new_height[[1]] == previous_height[[1]]) {
message("Se alcanzó el final de la página.")
break
}
}
}
# Llamar a la función para desplazarse al final de la página
scroll_to_bottom(remDr)
remDr$findElements("id", "onesignal-slidedown-cancel-button")[[1]]$clickElement()
xpath_boton_espania <- "//a[@href='https://www.infobae.com/espana/']"
boton_espania <- remDr$findElement(using = "xpath", value = xpath_boton_espania)
boton_espania$clickElement()
remDr$findElements("id", "hamburger-icon")[[1]]$clickElement()
remDr$findElements("id", "search-icon")[[1]]$clickElement()
search_bar <- remDr$findElement(using = "id", value = "queryly_query")
search_bar$sendKeysToElement(list("deportivo la coruña campeon"))
# Función para desplazarse al final de la página
scroll_to_bottom <- function(driver, max_attempts = 10, delay = 2) {
for (i in 1:max_attempts) {
# Obtener la altura actual de la página
previous_height <- remDr$executeScript("return document.body.scrollHeight")
# Desplazarse al final
remDr$executeScript("window.scrollTo(0, document.body.scrollHeight);")
# Esperar un momento para permitir que se cargue el contenido
Sys.sleep(delay)
# Verificar si la altura cambió
new_height <- remDr$executeScript("return document.body.scrollHeight")
if (new_height[[1]] == previous_height[[1]]) {
message("Se alcanzó el final de la página.")
break
}
}
}
# Llamar a la función para desplazarse al final de la página
scroll_to_bottom(remDr)
page_source <- remDr$getPageSource()[[1]]
page <- read_html(page_source)
raiz <- "https://www.infobae.com"
links <- links[!duplicated(links) ]
raiz <- "https://www.infobae.com"
links_completos <- str_c(raiz, links)
links_completos
links <- page %>%
html_nodes("div.queryly_item_title") %>%
html_elements("a") %>%
html_attr("href")
links
links <- links[!duplicated(links) ]
raiz <- "https://www.infobae.com"
links_completos <- str_c(raiz, links)
links_completos
tabla_noticias <- function(links){
noticia <- read_html(links)
titulo <- noticia %>%
html_element("h1") %>%
html_text() %>%
str_squish()
cuerpo <- noticia %>%
html_element("p.paragraph") %>%
html_text() %>%
str_squish()
fecha  <- noticia %>%
html_element("span.sharebar-article-date") %>%
html_text() %>%
str_squish()
autor  <- noticia %>%
html_element("span.author-name") %>%
html_text() %>%
str_squish()
web <- links
tabla_final <- as.data.frame(cbind("titulo"=titulo, "autor" = autor,  "cuerpo"=cuerpo,
"fecha" = fecha, "Link" = web
))
return(tabla_final)
}
noticias <- tibble(
titulo=character(),
cuerpo=character(),
fecha=character(),
autor= character()
)
print(paste("Se encontraron", length(links_completos), "noticias\n"))
for(i in 1:length(links_completos)){
print(paste("Obteniendo información de noticia:\n ",links_completos[i]))
resultado <- tabla_noticias(links_completos[i])
noticias <- noticias %>%
bind_rows(resultado)
}
View(noticias)
knitr::opts_chunk$set(echo = TRUE)
rd <- rsDriver(browser = "firefox",
chromever = NULL,
port= 4453L)
library(RSelenium)
library(tidyverse)
library(rvest)
library(Rcrawler)
rd <- rsDriver(browser = "firefox",
chromever = NULL,
port= 4453L)
remDr <- rd[["client"]]
remDr$navigate("https://www.infobae.com/")
remDr$maxWindowSize()
remDr$findElements("id", "onesignal-slidedown-cancel-button")[[1]]$clickElement()
remDr$findElements("id", "hamburger-icon")[[1]]$clickElement()
remDr$findElements("id", "search-icon")[[1]]$clickElement()
Sys.sleep(5)
search_bar <- remDr$findElement(using = "id", value = "queryly_query")
search_bar$sendKeysToElement(list("web scraping"))
close()
close.connection()
rd <- rsDriver(browser = "firefox",
chromever = NULL,
port= 4454L)
remDr <- rd[["client"]]
remDr$navigate("https://www.infobae.com/")
remDr$maxWindowSize()
Sys.sleep(5)
remDr$findElements("id", "onesignal-slidedown-cancel-button")[[1]]$clickElement()
Sys.sleep(3)
remDr$findElements("id", "hamburger-icon")[[1]]$clickElement()
Sys.sleep(3)
remDr$findElements("id", "search-icon")[[1]]$clickElement()
search_bar <- remDr$findElement(using = "id", value = "queryly_query")
search_bar$sendKeysToElement(list("web scraping"))
pagina_fuente <- remDr$getPageSource()[[1]]
pagina <- read_html(pagina_fuente)
titles <- page %>% html_nodes("div.queryly_item_title") %>%
html_text() %>%
str_squish()
titles <- pagina %>% html_nodes("div.queryly_item_title") %>%
html_text() %>%
str_squish()
length(titles)
knitr::opts_chunk$set(echo = TRUE)
noticias_barcelona <- readRDS("./noticias_barcelona.RDS")
noticias_barcelona <- readRDS("../Clase_2_ws/noticias_barcelona.RDS")
require(rvest)
require(tidyverse)
require(here)
require(openxlsx)
require(pander)
require(xml2)
require(RVerbalExpressions)
require(rapport)
require(wordcloud2)
library(tidytext)
library(htmlwidgets)
require(openxlsx)
View(noticias_barcelona)
palabraS_noticias <- noticias_barcelona %>%
mutate(entry_number = row_number())
View(palabraS_noticias)
palabras_noticias <- noticias_barcelona %>%
mutate(entry_number = row_number()) %>%
unnest_tokens(output = word,
input = cuerpo)
View(palabras_noticias)
palabras_noticias <- noticias_barcelona %>%
mutate(entry_number = row_number()) %>%
unnest_tokens(output = word,
input = cuerpo) %>%
group_by(autor, word) %>%
summarise(n = n()) %>%
arrange(desc(n))
View(palabras_noticias)
View(palabraS_noticias)
View(noticias_barcelona)
View(palabras_noticias)
noticias_tf_idf <- palabraS_noticias %>%
bind_tf_idf(word,autor , n)
noticias_tf_idf <- palabras_noticias %>%
bind_tf_idf(word,autor , n)
View(noticias_tf_idf)
noticias_tf_idf %>%
arrange(desc(tf_idf))
View(noticias_tf_idf)
unique(noticias_madrid$autor)
unique(noticias_barcelona$autor)
jorge <- noticias_tf_idf %>%
filter(autor == "Jorge de Vivero") %>%
arrange(-tf_idf)
jorge
View(jorge)
jose <- noticias_tf_idf %>%
filter(autor == "José Castro López")  %>%
arrange(-tf_idf)
jose
View(jose)
noticias_jose <- noticias_barcelona %>%
filter(autor == "José Castro López")
View(noticias_jose)
noticias_jose$cuerpo
noticias_jorge <- noticias_barcelona %>%
filter(autor == "Jorge de Vivero")
View(noticias_barcelona)
noticias_victor <- noticias_barcelona %>%
filter(autor == "Víctor Méndez")
View(noticias_victor)
victor <- noticias_tf_idf %>%
filter(autor == "Víctor Méndez") %>%
arrange(-tf_idf)
victor
View(victor)
knitr::opts_chunk$set(echo = TRUE)
library(RSelenium)
library(tidyverse)
library(rvest)
library(Rcrawler)
rd <- rsDriver(browser = "firefox",
chromever = NULL,
port= 4445L)
remDr <- rd[["client"]]
library(rJava)
rd <- rsDriver(browser = "firefox",
chromever = NULL,
port= 4445L)
remDr <- remoteDriver(remoteServerAddr = "localhost",
port = 4444L,
browserName = "firefox")
remDr$open()
remDr <- remoteDriver(remoteServerAddr = "localhost",
port = 4447L,
browserName = "firefox")
remDr$open()
rd <- rsDriver(browser = "firefox",
chromever = NULL,
port= 4446L)
rd <- rsDriver(browser = "firefox",
chromever = NULL,
port= 4448L)
remDr <- rd[["client"]]
remDr$navigate("https://www.infobae.com/")
remDr$maxWindowSize()
remDr$findElements("id", "onesignal-slidedown-cancel-button")[[1]]$clickElement()
Sys.sleep(3)
remDr$findElements("id", "hamburger-icon")[[1]]$clickElement()
Sys.sleep(3)
remDr$findElements("id", "search-icon")[[1]]$clickElement()
search_bar <- remDr$findElement(using = "id", value = "queryly_query")
Sys.sleep(3)
remDr$findElements("id", "search-icon")[[1]]$clickElement()
search_bar <- remDr$findElement(using = "id", value = "queryly_query")
search_bar$sendKeysToElement(list("web scraping"))
pagina_fuente <- remDr$getPageSource()[[1]]
pagina <- read_html(pagina_fuente)
titles <- pagina %>%
html_nodes("div.queryly_item_title") %>%
html_text() %>%
str_squish()
length(titles)
titles
length(titles)
remDr$executeScript("window.scrollTo(0, document.body.scrollHeight);")
Sys.sleep(5)
remDr$executeScript("window.scrollTo(0, document.body.scrollHeight);")
Sys.sleep(5)
# Función para desplazarse al final de la página
scroll_to_bottom <- function(driver, max_attempts = 4, delay = 4) {
for (i in 1:max_attempts) {
# Obtiene la altura actual de la página
previous_height <- remDr$executeScript("return document.body.scrollHeight")
# Se desplaza al final
remDr$executeScript("window.scrollTo(0, document.body.scrollHeight);")
# Esperar en segundos (parámetro de la función)
Sys.sleep(delay)
# Chequea si la altura cambió
new_height <- remDr$executeScript("return document.body.scrollHeight")
# Si la altura anterior de la página y la altura actual son igual, para.
# También para luego de 10 intentos.
if (new_height[[1]] == previous_height[[1]]) {
message("Se alcanzó el final de la página.")
break
}
}
}
# Llamar a la función para desplazarse al final de la página
scroll_to_bottom(remDr)
# Función para desplazarse al final de la página
scroll_to_bottom <- function(driver, max_attempts = 4, delay = 4) {
for (i in 1:max_attempts) {
# Obtiene la altura actual de la página
previous_height <- remDr$executeScript("return document.body.scrollHeight")
# Se desplaza al final
remDr$executeScript("window.scrollTo(0, document.body.scrollHeight);")
# Esperar en segundos (parámetro de la función)
Sys.sleep(delay)
# Chequea si la altura cambió
new_height <- remDr$executeScript("return document.body.scrollHeight")
# Si la altura anterior de la página y la altura actual son igual, para.
# También para luego de 10 intentos.
if (new_height[[1]] == previous_height[[1]]) {
message("Se alcanzó el final de la página.")
break
}
}
}
# Llamar a la función para desplazarse al final de la página
scroll_to_bottom(remDr)
pagina_fuente <- remDr$getPageSource()[[1]]
pagina <- read_html(pagina_fuente)
titles <- pagina %>% html_nodes("div.queryly_item_title") %>%
html_text() %>%
str_squish()
length(titles)
remDr$executeScript("window.scrollTo(0, document.body.scrollHeight);")
Sys.sleep(5)
remDr$executeScript("window.scrollTo(0, document.body.scrollHeight);")
Sys.sleep(5)
remDr$executeScript("window.scrollTo(0, document.body.scrollHeight);")
Sys.sleep(5)
remDr$executeScript("window.scrollTo(0, document.body.scrollHeight);")
Sys.sleep(5)
remDr$executeScript("window.scrollTo(0, document.body.scrollHeight);")
Sys.sleep(5)
pagina_fuente <- remDr$getPageSource()[[1]]
pagina <- read_html(pagina_fuente)
titles <- pagina %>% html_nodes("div.queryly_item_title") %>%
html_text() %>%
str_squish()
length(titles)
titles
links <- pagina %>%
html_nodes("div.queryly_item_title") %>%
html_elements("a") %>%
html_attr("href")
links
links <- links[!duplicated(links) ]
raiz <- "https://www.infobae.com"
links_completos <- str_c(raiz, links)
links_completos
noticia <-  read_html(links_completos[1])
titulo <- noticia %>%
html_element("h1") %>%
html_text() %>%
str_squish()
print(titulo)
titulo <- noticia %>%
html_element("h1") %>%
html_text() %>%
str_squish()
print(titulo)
cuerpo <- noticia %>%
html_element("p.paragraph") %>%
html_text() %>%
str_squish()
print(cuerpo)
fecha  <- noticia %>%
html_element("span.sharebar-article-date") %>%
html_text() %>%
str_squish()
print(fecha)
autor  <- noticia %>%
html_element("span.author-name") %>%
html_text() %>%
str_squish()
print(autor)
df_noticia <- as.data.frame(cbind("Titulo" = titulo, "Texto"= cuerpo,
"Fecha" = fecha, "Autor" = autor,
"Link" = links_completos[1]))
df_noticia
View(df_noticia)
noticias <- tibble(
titulo=character(),
cuerpo=character(),
fecha=character(),
autor= character()
)
View(noticias)
rd <- rsDriver(browser = "firefox",
chromever = NULL,
port= 4457L)
remDr <- rd[["client"]]
remDr$navigate("https://www.infobae.com/")
remDr$maxWindowSize()
Sys.sleep(10)
remDr$findElements("id", "onesignal-slidedown-cancel-button")[[1]]$clickElement()
Sys.sleep(3)
remDr$findElements("id", "hamburger-icon")[[1]]$clickElement()
Sys.sleep(2)
remDr$findElements("id", "search-icon")[[1]]$clickElement()
Sys.sleep(2)
search_bar <- remDr$findElement(using = "id", value = "queryly_query")
Sys.sleep(2)
search_bar$sendKeysToElement(list("web scraping"))
Sys.sleep(5)
remDr$executeScript("window.scrollTo(0, document.body.scrollHeight);")
Sys.sleep(5)
remDr$executeScript("window.scrollTo(0, document.body.scrollHeight);")
Sys.sleep(5)
page_source <- remDr$getPageSource()[[1]]
Sys.sleep(3)
page <- read_html(page_source)
titles <- page %>% html_nodes("div.queryly_item_title") %>%
html_text() %>%
str_squish()
links <- page %>%
html_nodes("div.queryly_item_title") %>%
html_elements("a") %>%
html_attr("href")
links <- links[!duplicated(links) ]
raiz <- "https://www.infobae.com"
links_completos <- str_c(raiz, links)
tabla_noticias <- function(links){
noticia <- read_html(links)
titulo <- noticia %>%
html_element("h1") %>%
html_text() %>%
str_squish()
cuerpo <- noticia %>%
html_element("p.paragraph") %>%
html_text() %>%
str_squish()
fecha  <- noticia %>%
html_element("span.sharebar-article-date") %>%
html_text() %>%
str_squish()
autor  <- noticia %>%
html_element("span.author-name") %>%
html_text() %>%
str_squish()
web <- links
tabla_final <- as.data.frame(cbind("titulo"=titulo, "autor" = autor,  "cuerpo"=cuerpo,
"fecha" = fecha, "Link" = web
))
return(tabla_final)
}
noticias <- tibble(
titulo=character(),
cuerpo=character(),
fecha=character(),
autor= character()
)
print(paste("Se encontraron", length(links_completos), "noticias\n"))
for(i in 1:length(links_completos)){
print(paste("Obteniendo información de noticia:\n ",links_completos[i]))
resultado <- tabla_noticias(links_completos[i])
noticias <- noticias %>%
bind_rows(resultado)
}
View(noticias)
noticias$cuerpo[2]
library(openxlsx)
write.xlsx(noticias, "noticias_scraping_infobae.xlsx")
getwd()
url <- "https://www.instagram.com/bachilleratopopularcasabierta/"
ig_casa <- rvest::read_html_live(url)
ig_casa_list <- as.list(ig_casa)
posteos <- ig_casa$html_elements("body")[3] %>%
html_text2()
posteos
posts <- unlist(strsplit(posteos, "\n"))
posts <- trimws(posts)
posts <- posts[posts != ""]
posts
df_posts <- data.frame(
Post = seq_along(posts),  # Número del post
Contenido = posts,        # Texto del post
stringsAsFactors = FALSE)
View(df_posts)
df_filtrado <- df_posts %>%
filter(Contenido != "Carousel")
View(df_filtrado)
df_filtrado <- df_filtrado %>%
slice(14:37)
ig_casa$session$close()
"2025-01-20"+days(60)
library(lubridate)
"2025-01-20"+days(60)
as.Date("2025-01-20")+days(60)
