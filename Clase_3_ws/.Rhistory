topicos_wider <- doc_2_topics %>%
pivot_wider( names_from = "topic", values_from = "gamma")
View(topicos_wider)
revistas_tidy %>%
filter(id==2571) %>%
group_by(id, word) %>%
summarise(n=n()) %>%
select(word, n) %>%
arrange(desc(n))
View(revistas_tidy)
numero_2571 <- revistas_tidy %>%
filter(id==2571) %>%
group_by(id, word) %>%
summarise(n=n()) %>%
select(word, n) %>%
arrange(desc(n))
View(numero_2571)
View(topicos_wider)
numero_2092 <- revistas_tidy %>%
filter(id==2092) %>%
group_by(id, word) %>%
summarise(n=n()) %>%
select(word, n) %>%
arrange(desc(n))
View(numero_2092)
View(revistas)
revistas %>%
filter(id==2571) %>%
select(text) %>%
pull()
View(doc_2_topics)
doc_2_topics %>%
rename(id = document) %>% # tenemos que renombrar la columna para que pueda hacerse el join
mutate(id = as.integer(id)) %>%
left_join(revistas %>% select(id, categoria) %>% unique()) %>%
group_by(categoria, topic) %>%
summarise(mean = mean(gamma)*100
) %>%
ggplot() +
geom_col(aes(x=topic, y=mean, fill=categoria), position='dodge') +
theme_minimal()
knitr::opts_chunk$set(echo = TRUE)
library(tidyverse)
library(topicmodels)
library(tidytext)
library(tictoc)
revistas <- read_csv('./data/revistas_limpias_final.csv')
head(revistas)
View(revistas)
revistas <- revistas %>%
mutate(text = stringi::stri_trans_general(text, "Latin-ASCII"),
titulo = stringi::stri_trans_general(titulo, "Latin-ASCII"))
revistas <- revistas %>%
mutate(text = str_replace_all(text, '[[:digit:]]+', ''))
revistas_tidy <- revistas %>%
unnest_tokens(word, text)
head(revistas_tidy)
View(revistas_tidy)
revistas_tidy %>%
group_by(word) %>%
summarise( n = n() ) %>%
arrange(desc(n))
stop_words <- read_delim('./data/stopwords.txt',
delim = '\t',
col_names = c('word')) %>%
mutate(word=stringi::stri_trans_general(word, "Latin-ASCII"))
## Aquí agregamos algunas palabras al listado de stopwords...
stop_words <- stop_words %>%
bind_rows( tibble(word=c('ano', 'anos', 'ohlala', 'foto', 'the')))
## Ahora, las eliminamos
revistas_tidy <- revistas_tidy %>%
anti_join(stop_words, by="word")
revistas_tidy %>%
group_by(word) %>%
summarise(n=n()) %>%
arrange(desc(n))
hombre_mujer <- revistas_tidy %>%
group_by(categoria,word) %>%
summarise(n=n()) %>%
arrange(desc(n))
View(hombre_mujer)
hombres <- revistas_tidy %>%
group_by(categoria,word) %>%
summarise(n=n()) %>%
arrange(desc(n)) %>%
filter(categoria == "Hombre")
mujeres <- revistas_tidy %>%
group_by(categoria,word) %>%
summarise(n=n()) %>%
arrange(desc(n)) %>%
filter(categoria == "Mujer")
head(mujeres)
View(hombres)
View(mujeres)
word_counts <- revistas_tidy %>%
group_by(id, word) %>%
summarise(n=n()) %>%
ungroup()
head(word_counts)
documento_1 <- word_counts %>%
filter(id == 1) %>%
arrange(-n)
View(word_counts)
View(documento_1)
disc_dtm <- word_counts %>%
cast_dtm(id, word, n)
disc_dtm
View(disc_dtm)
lda_4 <- LDA(disc_dtm, k=4, control = list(seed = 1234))
View(disc_dtm)
options(scipen=999)
ap_topics <- tidy(lda_4, matrix = "beta") # Si esta línea  tira algún error,  install.packages("reshape2")
ap_topics
unique(ap_topics$topic)
View(ap_topics)
ap_top_terms <- ap_topics %>%
group_by(topic) %>%
slice_max(beta, n = 15) %>%
#ungroup() %>%
arrange(topic, -beta)
ap_top_terms %>%
mutate(term = reorder_within(term, beta, topic)) %>%
ggplot(aes(beta, term, fill = factor(topic))) +
geom_col(show.legend = FALSE) +
facet_wrap(~ topic, scales='free_y') +
scale_y_reordered() +
theme_minimal()
options(scipen = 999)
doc_2_topics <- tidy(lda_4, matrix = "gamma")
documentos_gamma <-  doc_2_topics %>%
mutate(gamma = round(gamma, 5))
View(documentos_gamma)
doc_2_topics %>%
filter(topic == 3 | topic == 4) %>%
mutate(gamma = round(gamma, 5))
View(doc_2_topics)
topicos_wider <- doc_2_topics %>%
pivot_wider( names_from = "topic", values_from = "gamma")
View(topicos_wider)
numero_2571 <- revistas_tidy %>%
filter(id==2571) %>%
group_by(id, word) %>%
summarise(n=n()) %>%
select(word, n) %>%
arrange(desc(n))
numero_2092 <- revistas_tidy %>%
filter(id==2092) %>%
group_by(id, word) %>%
summarise(n=n()) %>%
select(word, n) %>%
arrange(desc(n))
View(numero_2571)
View(numero_2092)
revistas %>%
filter(id==2571) %>%
select(text) %>%
pull()
doc_2_topics %>%
rename(id = document) %>% # tenemos que renombrar la columna para que pueda hacerse el join
mutate(id = as.integer(id)) %>%
left_join(revistas %>% select(id, categoria) %>% unique()) %>%
group_by(categoria, topic) %>%
summarise(mean = mean(gamma)*100
) %>%
ggplot() +
geom_col(aes(x=topic, y=mean, fill=categoria), position='dodge') +
theme_minimal()
doc_2_topics %>%
rename(id = document) %>% # tenemos que renombrar la columna para que pueda hacerse el join
mutate(id = as.integer(id)) %>%
left_join(revistas %>% select(id, categoria) %>% unique()) %>%
group_by(categoria, topic) %>%
summarise(mean = mean(gamma)*100
) %>%
ggplot() +
geom_col(aes(x=topic, y=mean, fill=categoria), position='dodge') +
theme_minimal()
revistas <- read_csv('./data/revistas_limpias_final.csv')
head(revistas)
revistas <- revistas %>%
mutate(text = stringi::stri_trans_general(text, "Latin-ASCII"),
titulo = stringi::stri_trans_general(titulo, "Latin-ASCII"))
revistas <- revistas %>%
mutate(text = str_replace_all(text, '[[:digit:]]+', ''))
revistas_tidy <- revistas %>%
unnest_tokens(word, text)
head(revistas_tidy)
stop_words <- read_delim('./data/stopwords.txt',
delim = '\t',
col_names = c('word')) %>%
mutate(word=stringi::stri_trans_general(word, "Latin-ASCII"))
## Aquí agregamos algunas palabras al listado de stopwords...
stop_words <- stop_words %>%
bind_rows( tibble(word=c('ano', 'anos', 'ohlala', 'foto', 'the')))
## Ahora, las eliminamos
revistas_tidy <- revistas_tidy %>%
anti_join(stop_words, by="word")
View(revistas_tidy)
revistas_tidy %>%
group_by(word) %>%
summarise(n=n()) %>%
arrange(desc(n))
View(revistas)
hombre_mujer <- revistas_tidy %>%
group_by(categoria,word) %>%
summarise(n=n()) %>%
arrange(desc(n))
hombres <- revistas_tidy %>%
group_by(categoria,word) %>%
summarise(n=n()) %>%
arrange(desc(n)) %>%
filter(categoria == "Hombre")
mujeres <- revistas_tidy %>%
group_by(categoria,word) %>%
summarise(n=n()) %>%
arrange(desc(n)) %>%
filter(categoria == "Mujer")
head(mujeres)
word_counts <- revistas_tidy %>%
group_by(id, word) %>%
summarise(n=n()) %>%
ungroup()
head(word_counts)
documento_1 <- word_counts %>%
filter(id == 1) %>%
arrange(-n)
View(word_counts)
View(documento_1)
disc_dtm <- word_counts %>%
cast_dtm(id, word, n)
disc_dtm
lda_4 <- LDA(disc_dtm, k=4, control = list(seed = 1234))
options(scipen=999)
ap_topics <- tidy(lda_4, matrix = "beta") # Si esta línea  tira algún error,  install.packages("reshape2")
ap_topics
unique(ap_topics$topic)
View(ap_topics)
ap_top_terms <- ap_topics %>%
group_by(topic) %>%
slice_max(beta, n = 15) %>%
#ungroup() %>%
arrange(topic, -beta)
ap_top_terms %>%
mutate(term = reorder_within(term, beta, topic)) %>%
ggplot(aes(beta, term, fill = factor(topic))) +
geom_col(show.legend = FALSE) +
facet_wrap(~ topic, scales='free_y') +
scale_y_reordered() +
theme_minimal()
options(scipen = 999)
doc_2_topics <- tidy(lda_4, matrix = "gamma")
documentos_gamma <-  doc_2_topics %>%
mutate(gamma = round(gamma, 5))
View(documentos_gamma)
topicos_wider <- doc_2_topics %>%
pivot_wider( names_from = "topic", values_from = "gamma")
View(topicos_wider)
numero_2571 <- revistas_tidy %>%
filter(id==2571) %>%
group_by(id, word) %>%
summarise(n=n()) %>%
select(word, n) %>%
arrange(desc(n))
numero_2092 <- revistas_tidy %>%
filter(id==2092) %>%
group_by(id, word) %>%
summarise(n=n()) %>%
select(word, n) %>%
arrange(desc(n))
revistas %>%
filter(id==2571) %>%
select(text) %>%
pull()
View(revistas)
View(doc_2_topics)
setwd("C:/Users/dpach/OneDrive - sociales.UBA.ar/CURSO_WEB_SCRAPING_HAB/Clase_3_ws")
knitr::opts_chunk$set(echo = TRUE)
#install.packages("Rcrawler", dependencies = TRUE)
library(Rcrawler)
Rcrawler(Website = "https://quotes.toscrape.com",
no_cores = 4, # numero de procesos que ejecutará la tarea
no_conn = 4) # numero de conexiones simultaneas
ListProjects()
links <- ContentScraper(Url = "https://quotes.toscrape.com",
XpathPatterns = "//*/a/@href" ,
ManyPerPattern = TRUE)
unlist(links)
Rcrawler(Website = "https://quotes.toscrape.com", no_cores = 4, no_conn = 4,
ExtractCSSPat = c(".author-title"), PatternsNames = c("title"))
Rcrawler(Website = "https://quotes.toscrape.com", no_cores = 4, no_conn = 4,
ExtractCSSPat = c(".author-description"))
Rcrawler(Website = "https://quotes.toscrape.com", no_cores = 4, no_conn = 4,
ExtractCSSPat = c(".author-title",".author-description"), PatternsNames = c("title",
"description"))
library(tidyverse)
library(topicmodels)
library(tidytext)
library(tictoc)
revistas <- read_csv('./data/revistas_limpias_final.csv')
head(revistas)
View(revistas)
unique(revistas$categoria)
revistas <- revistas %>%
mutate(text = stringi::stri_trans_general(text, "Latin-ASCII"),
titulo = stringi::stri_trans_general(titulo, "Latin-ASCII"))
View(revistas)
revistas <- revistas %>%
mutate(text = str_replace_all(text, '[[:digit:]]+', ''))
revistas_tidy <- revistas %>%
unnest_tokens(word, text)
head(revistas_tidy)
View(revistas_tidy)
View(revistas)
print(revistas$text[1])
agrupado_revistas_tidy <- revistas_tidy %>%
group_by(word) %>%
summarise( n = n() ) %>%
arrange(desc(n))
View(agrupado_revistas_tidy)
stop_words <- read_delim('./data/stopwords.txt',
delim = '\t',
col_names = c('word')) %>%
mutate(word=stringi::stri_trans_general(word, "Latin-ASCII"))
View(stop_words)
tibble(word=c('ano', 'anos', 'ohlala', 'foto', 'the',
'aag'))
tibble(word=c('ano', 'anos', 'ohlala', 'foto', 'the',
'aag'))
## Aquí agregamos algunas palabras al listado de stopwords...
stop_words <- stop_words %>%
bind_rows( tibble(word=c('ano', 'anos', 'ohlala', 'foto', 'the',
'aag')))
View(stop_words)
View(stop_words)
View(revistas_tidy)
## Ahora, las eliminamos
revistas_tidy <- revistas_tidy %>%
anti_join(stop_words, by="word")
revistas_tidy %>%
group_by(word) %>%
summarise(n=n()) %>%
arrange(desc(n))
sin_sw <- revistas_tidy %>%
group_by(word) %>%
summarise(n=n()) %>%
arrange(desc(n))
View(sin_sw)
View(revistas)
View(revistas_tidy)
hombre_mujer <- revistas_tidy %>%
group_by(categoria,word) %>%
summarise(n=n()) %>%
arrange(desc(n))
View(hombre_mujer)
hombres <- revistas_tidy %>%
group_by(categoria,word) %>%
summarise(n=n()) %>%
arrange(desc(n)) %>%
filter(categoria == "Hombre")
View(hombres)
mujeres <- revistas_tidy %>%
group_by(categoria,word) %>%
summarise(n=n()) %>%
arrange(desc(n)) %>%
filter(categoria == "Mujer")
head(mujeres)
View(mujeres)
View(hombres)
paste("buenos", "aires", sep="-")
View(sin_sw)
View(stop_words)
## Aquí agregamos algunas palabras al listado de stopwords...
stop_words <- stop_words %>%
bind_rows( tibble(word=c('ano', 'anos', 'ohlala', 'foto', 'the',
'aag', 'aires', 'aire')))
## Ahora, las eliminamos
revistas_tidy <- revistas_tidy %>%
anti_join(stop_words, by="word")
sin_sw <- revistas_tidy %>%
group_by(word) %>%
summarise(n=n()) %>%
arrange(desc(n))
hombre_mujer <- revistas_tidy %>%
group_by(categoria,word) %>%
summarise(n=n()) %>%
arrange(desc(n))
hombres <- revistas_tidy %>%
group_by(categoria,word) %>%
summarise(n=n()) %>%
arrange(desc(n)) %>%
filter(categoria == "Hombre")
mujeres <- revistas_tidy %>%
group_by(categoria,word) %>%
summarise(n=n()) %>%
arrange(desc(n)) %>%
filter(categoria == "Mujer")
head(mujeres)
word_counts <- revistas_tidy %>%
group_by(id, word) %>%
summarise(n=n()) %>%
ungroup()
View(word_counts)
documento_1 <- word_counts %>%
filter(id == 1) %>%
arrange(-n)
View(documento_1)
documento_wider <- pivot_wider(names_from = word, values_from = n)
documento_wider <- pivot_wider(names_from = "word", values_from = "n")
documento_wider <- pivot_wider(documento_1,names_from = word, values_from = n)
View(documento_wider)
View(word_counts)
?cast_dtm
disc_dtm <- word_counts %>%
cast_dtm(id, word, n)
disc_dtm
?LDA
lda_4 <- LDA(disc_dtm, k=4, control = list(seed = 1234))
View(lda_4)
ap_topics <- tidy(lda_4, matrix = "beta") # Si esta línea  tira algún error,  install.packages("reshape2")
ap_topics
unique(ap_topics$topic)
View(ap_topics)
ap_top_terms <- ap_topics %>%
group_by(topic) %>%
slice_max(beta, n = 15) %>%
#ungroup() %>%
arrange(topic, -beta)
ap_top_terms %>%
mutate(term = reorder_within(term, beta, topic)) %>%
ggplot(aes(beta, term, fill = factor(topic))) +
geom_col(show.legend = FALSE) +
facet_wrap(~ topic, scales='free_y') +
scale_y_reordered() +
theme_minimal()
View(ap_top_terms)
View(ap_topics)
vida <- ap_topics %>%
filter(term== "vida")
View(vida)
ap_top_terms %>%
mutate(term = reorder_within(term, beta, topic)) %>%
ggplot(aes(beta, term, fill = factor(topic))) +
geom_col(show.legend = FALSE) +
facet_wrap(~ topic, scales='free_y') +
scale_y_reordered() +
theme_minimal()
doc_2_topics <- tidy(lda_4, matrix = "gamma")
View(doc_2_topics)
doc_2_topics <- doc_2_topics %>%
mutate(document = as.numeric(document))
View(revistas)
documentos_gamma <-  doc_2_topics %>%
mutate(gamma = round(gamma, 5))
View(documentos_gamma)
doc_2_topics %>%
filter(topic == 3 | topic == 4) %>%
mutate(gamma = round(gamma, 5))
topicos_3_4 <- doc_2_topics %>%
filter(topic == 3 | topic == 4) %>%
mutate(gamma = round(gamma, 5))
View(topicos_3_4)
topicos_wider <- doc_2_topics %>%
pivot_wider( names_from = "topic", values_from = "gamma")
View(doc_2_topics)
View(topicos_wider)
View(topicos_wider)
View(revistas_tidy)
numero_2571 <- revistas_tidy %>%
filter(id==2571) %>%
group_by(id, word) %>%
summarise(n=n()) %>%
select(word, n) %>%
arrange(desc(n))
View(numero_2571)
numero_2571 <- revistas_tidy %>%
filter(id==2571)
numero_2571 <- revistas_tidy %>%
filter(id==2571) %>%
group_by(id, word) %>%
summarise(n=n()) %>%
select(word, n) %>%
arrange(desc(n))
numero_2571_articulo <- revistas %>%
filter(id = 2571)
View(revistas)
numero_2571_articulo <- revistas %>%
filter(id == 2571)
View(numero_2571_articulo)
numero_2092 <- revistas_tidy %>%
filter(id==2092) %>%
group_by(id, word) %>%
summarise(n=n()) %>%
select(word, n) %>%
arrange(desc(n))
View(numero_2092)
View(topicos_wider)
numero_2092_articulo <- revistas %>%
filter(id == 2092)
View(numero_2092_articulo)
View(doc_2_topics)
View(revistas)
promedios_gamma <- doc_2_topics %>%
rename(id = document) %>% # tenemos que renombrar la columna para que pueda hacerse el join
mutate(id = as.integer(id)) %>%
left_join(revistas %>% select(id, categoria) %>% unique()) %>%
group_by(categoria, topic) %>%
summarise(mean = mean(gamma)*100
)
View(promedios_gamma)
ggplot(promedios_gamma) +
geom_col(aes(x=topic, y=mean, fill=categoria), position='dodge') +
theme_minimal()
