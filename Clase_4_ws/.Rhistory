knitr::opts_chunk$set(echo = TRUE)
library(tidyverse)
library(topicmodels)
library(tidytext)
library(tictoc)
revistas <- read_csv('./data/revistas_limpias_final.csv')
head(revistas)
revistas <- revistas %>%
mutate(text = stringi::stri_trans_general(text, "Latin-ASCII"),
titulo = stringi::stri_trans_general(titulo, "Latin-ASCII"))
revistas <- revistas %>%
mutate(text = str_replace_all(text, '[[:digit:]]+', ''))
revistas_tidy <- revistas %>%
unnest_tokens(word, text)
head(revistas_tidy)
View(revistas_tidy)
revistas_tidy %>%
group_by(word) %>%
summarise(n=n()) %>%
arrange(desc(n))
stop_words <- read_delim('./data/stopwords.txt',
delim = '\t',
col_names = c('word')) %>%
mutate(word=stringi::stri_trans_general(word, "Latin-ASCII"))
## Aquí agregamos algunas palabras al listado de stopwords...
stop_words <- stop_words %>%
bind_rows( tibble(word=c('ano', 'anos', 'ohlala', 'foto', 'the')))
## Ahora, las eliminamos
revistas_tidy <- revistas_tidy %>%
anti_join(stop_words)
revistas_tidy %>%
group_by(word) %>%
summarise(n=n()) %>%
arrange(desc(n))
revistas_tidy %>%
group_by(categoria,word) %>%
summarise(n=n()) %>%
arrange(desc(n))
hombres <- revistas_tidy %>%
group_by(categoria,word) %>%
summarise(n=n()) %>%
arrange(desc(n)) %>%
filter(categoria == "Hombre")
head(hombres)
mujeres <- revistas_tidy %>%
group_by(categoria,word) %>%
summarise(n=n()) %>%
arrange(desc(n)) %>%
filter(categoria == "Mujer")
head(mujeres)
word_counts <- revistas_tidy %>%
group_by(id, word) %>%
summarise(n=n()) %>%
ungroup()
head(word_counts)
View(word_counts)
View(word_counts)
disc_dtm <- word_counts %>%
cast_dtm(id, word, n)
disc_dtm
lda_4 <- LDA(disc_dtm, k=4, control = list(seed = 1234))
ap_topics <- tidy(lda_4, matrix = "beta") # Si esta línea  tira algún error,  install.packages("reshape2")
ap_topics
unique(ap_topics$topic)
View(ap_topics)
ap_top_terms <- ap_topics %>%
group_by(topic) %>%
slice_max(beta, n = 15) %>%
#ungroup() %>%
arrange(topic, -beta)
ap_top_terms %>%
mutate(term = reorder_within(term, beta, topic)) %>%
ggplot(aes(beta, term, fill = factor(topic))) +
geom_col(show.legend = FALSE) +
facet_wrap(~ topic, scales='free_y') +
scale_y_reordered() +
theme_minimal()
ap_top_terms <- ap_topics %>%
group_by(topic) %>%
slice_max(beta, n = 15) %>%
#ungroup() %>%
arrange(topic, -beta)
ap_top_terms %>%
mutate(term = reorder_within(term, beta, topic)) %>%
ggplot(aes(beta, term, fill = factor(topic))) +
geom_col(show.legend = FALSE) +
facet_wrap(~ topic, scales='free_y') +
#scale_y_reordered() +
theme_minimal()
ap_top_terms <- ap_topics %>%
group_by(topic) %>%
slice_max(beta, n = 15) %>%
#ungroup() %>%
arrange(topic, -beta)
ap_top_terms %>%
mutate(term = reorder_within(term, beta, topic)) %>%
ggplot(aes(beta, term, fill = factor(topic))) +
geom_col(show.legend = FALSE) +
facet_wrap(~ topic, scales='free_y') +
scale_y_reordered() +
theme_minimal()
options(scipen = 999)
doc_2_topics <- tidy(lda_4, matrix = "gamma")
doc_2_topics %>%
mutate(gamma = round(gamma, 5))
doc_2_topics %>%
filter(topic == 3 | topic == 4) %>%
mutate(gamma = round(gamma, 5))
topicos_wider <- doc_2_topics %>%
pivot_wider( names_from = "topic", values_from = "gamma")
View(topicos_wider)
revistas_tidy %>%
filter(id==2571) %>%
group_by(id, word) %>%
summarise(n=n()) %>%
select(word, n) %>%
arrange(desc(n))
revistas %>%
filter(id==2571) %>%
select(text) %>%
pull()
doc_2_topics %>%
rename(id = document) %>% # tenemos que renombrar la columna para que pueda hacerse el join
mutate(id = as.integer(id)) %>%
left_join(revistas %>% select(id, categoria) %>% unique()) %>%
group_by(categoria, topic) %>%
summarise(mean = mean(gamma)*100
) %>%
ggplot() +
geom_col(aes(x=topic, y=mean, fill=categoria), position='dodge') +
theme_minimal()
knitr::opts_chunk$set(echo = TRUE)
estatica <- read_html("https://www.forbes.com/top-colleges/")
library(RSelenium)
library(tidyverse)
library(rvest)
library(Rcrawler)
library(rJava)
estatica <- read_html("https://www.forbes.com/top-colleges/")
estatica %>% html_elements(".CustomTable_container__CkQ96")
dinamica <- read_html_live("https://www.forbes.com/top-colleges/")
dinamica <- read_html_live("https://www.forbes.com/top-colleges/")
dinamica$view()
filas <- dinamica %>%
html_elements(".CustomTable_container__CkQ96") %>%
html_table()
tabla <- as.data.frame(filas)
library(RSelenium)
library(tidyverse)
library(rvest)
library(Rcrawler)
library(rJava)
estatica <- read_html("https://www.forbes.com/top-colleges/")
estatica %>% html_elements("div.CustomTable_container__CkQ96")
estatica %>% html_elements("div.CustomTable_container__CkQ96")
dinamica <- read_html_live("https://www.forbes.com/top-colleges/")
dinamica$view()
filas <- dinamica %>%
html_elements(".CustomTable_container__CkQ96") %>%
html_table()
filas
tabla <- as.data.frame(filas)
View(tabla)
#install.packages("Rcrawler", dependencies = TRUE)
library(Rcrawler)
Rcrawler(Website = "https://quotes.toscrape.com",
no_cores = 4, # numero de procesos que ejecutará la tarea
no_conn = 4) # numero de conexiones simultaneas
ListProjects()
links<-ContentScraper(Url = "https://quotes.toscrape.com",
XpathPatterns = "//*/a/@href" ,
ManyPerPattern = TRUE)
unlist(links)
Rcrawler(Website = "https://quotes.toscrape.com", no_cores = 4, no_conn = 4,
ExtractCSSPat = c(".author-title"), PatternsNames = c("title"))
Rcrawler(Website = "https://quotes.toscrape.com", no_cores = 4, no_conn = 4,
ExtractCSSPat = c(".author-title",".author-description"), PatternsNames = c("title",
"description"))
library(tidyverse)
library(topicmodels)
library(tidytext)
library(tictoc)
revistas <- read_csv('./data/revistas_limpias_final.csv')
head(revistas)
View(revistas)
unique(revistas$categoria)
revistas$text[1]
revistas <- revistas %>%
mutate(text = stringi::stri_trans_general(text, "Latin-ASCII"),
titulo = stringi::stri_trans_general(titulo, "Latin-ASCII"))
revistas <- revistas %>%
mutate(text = str_replace_all(text, '[[:digit:]]+', ''))
revistas_tidy <- revistas %>%
unnest_tokens(word, text)
head(revistas_tidy)
View(revistas_tidy)
View(revistas)
revistas_tidy %>%
group_by(word) %>%
summarise( n = n() ) %>%
arrange(desc(n))
stop_words <- read_delim('./data/stopwords.txt',
delim = '\t',
col_names = c('word')) %>%
mutate(word=stringi::stri_trans_general(word, "Latin-ASCII"))
View(stop_words)
bind_rows( tibble(word=c('ano', 'anos', 'ohlala', 'foto', 'the')))
## Aquí agregamos algunas palabras al listado de stopwords...
stop_words <- stop_words %>%
bind_rows( tibble(word=c('ano', 'anos', 'ohlala', 'foto', 'the')))
View(stop_words)
View(revistas_tidy)
View(stop_words)
## Ahora, las eliminamos
revistas_tidy <- revistas_tidy %>%
anti_join(stop_words)
revistas_tidy %>%
group_by(word) %>%
summarise(n=n()) %>%
arrange(desc(n))
revistas_tidy %>%
group_by(word) %>%
summarise(n=n()) %>%
arrange(desc(n))
revistas_tidy %>%
group_by(categoria,word) %>%
summarise(n=n()) %>%
arrange(desc(n))
hombre_mujer <- revistas_tidy %>%
group_by(categoria,word) %>%
summarise(n=n()) %>%
arrange(desc(n))
View(hombre_mujer)
hombres <- revistas_tidy %>%
group_by(categoria,word) %>%
summarise(n=n()) %>%
arrange(desc(n)) %>%
filter(categoria == "Hombre")
View(hombres)
mujeres <- revistas_tidy %>%
group_by(categoria,word) %>%
summarise(n=n()) %>%
arrange(desc(n)) %>%
filter(categoria == "Mujer")
head(mujeres)
View(mujeres)
word_counts <- revistas_tidy %>%
group_by(id, word) %>%
summarise(n=n()) %>%
ungroup()
head(word_counts)
View(word_counts)
documento_1 <- word_counts %>%
filter(id == 1)
View(documento_1)
documento_1 <- word_counts %>%
filter(id == 1) %>%
arrange(-n)
disc_dtm <- word_counts %>%
cast_dtm(id, word, n)
disc_dtm
lda_4 <- LDA(disc_dtm, k=4, control = list(seed = 1234))
ap_topics <- tidy(lda_4, matrix = "beta") # Si esta línea  tira algún error,  install.packages("reshape2")
ap_topics
unique(ap_topics$topic)
View(ap_topics)
ap_top_terms <- ap_topics %>%
group_by(topic) %>%
slice_max(beta, n = 15) %>%
#ungroup() %>%
arrange(topic, -beta)
View(ap_top_terms)
ap_top_terms %>%
mutate(term = reorder_within(term, beta, topic)) %>%
ggplot(aes(beta, term, fill = factor(topic))) +
geom_col(show.legend = FALSE) +
facet_wrap(~ topic, scales='free_y') +
scale_y_reordered() +
theme_minimal()
options(scipen = 999)
doc_2_topics <- tidy(lda_4, matrix = "gamma")
doc_2_topics %>%
mutate(gamma = round(gamma, 5))
documentos_gamma <-  doc_2_topics %>%
mutate(gamma = round(gamma, 5))
View(documentos_gamma)
doc_2_topics %>%
filter(topic == 3 | topic == 4) %>%
mutate(gamma = round(gamma, 5))
topicos_wider <- doc_2_topics %>%
pivot_wider( names_from = "topic", values_from = "gamma")
View(topicos_wider)
revistas_tidy %>%
filter(id==2571) %>%
group_by(id, word) %>%
summarise(n=n()) %>%
select(word, n) %>%
arrange(desc(n))
View(revistas_tidy)
numero_2571 <- revistas_tidy %>%
filter(id==2571) %>%
group_by(id, word) %>%
summarise(n=n()) %>%
select(word, n) %>%
arrange(desc(n))
View(numero_2571)
View(topicos_wider)
numero_2092 <- revistas_tidy %>%
filter(id==2092) %>%
group_by(id, word) %>%
summarise(n=n()) %>%
select(word, n) %>%
arrange(desc(n))
View(numero_2092)
View(revistas)
revistas %>%
filter(id==2571) %>%
select(text) %>%
pull()
View(doc_2_topics)
doc_2_topics %>%
rename(id = document) %>% # tenemos que renombrar la columna para que pueda hacerse el join
mutate(id = as.integer(id)) %>%
left_join(revistas %>% select(id, categoria) %>% unique()) %>%
group_by(categoria, topic) %>%
summarise(mean = mean(gamma)*100
) %>%
ggplot() +
geom_col(aes(x=topic, y=mean, fill=categoria), position='dodge') +
theme_minimal()
